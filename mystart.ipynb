{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40723018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD JSONS   train_data e test_data\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Define the path to our data ---\n",
    "train_file_path = 'train.jsonl'\n",
    "test_file_path  = 'test.jsonl'\n",
    "\n",
    "train_data = []\n",
    "test_data  = []\n",
    "\n",
    "# --- Load TRAIN data ---\n",
    "print(f\"üì¶ Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            train_data.append(json.loads(line))\n",
    "    print(f\"‚úÖ Successfully loaded {len(train_data)} battles from train.\")\n",
    "    \n",
    "    # Show structure of first train battle\n",
    "    if train_data:\n",
    "        print(\"\\n--- Structure of the first train battle: ---\")\n",
    "        first_battle = train_data[0]\n",
    "        battle_for_display = first_battle.copy()\n",
    "        battle_for_display['battle_timeline'] = first_battle.get('battle_timeline', [])[:2]\n",
    "        print(json.dumps(battle_for_display, indent=4))\n",
    "        if len(first_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "\n",
    "\n",
    "# --- Load TEST data ---\n",
    "print(f\"\\nüì¶ Loading data from '{test_file_path}'...\")\n",
    "try:\n",
    "    with open(test_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            test_data.append(json.loads(line))\n",
    "    print(f\"‚úÖ Successfully loaded {len(test_data)} battles from test.\")\n",
    "    \n",
    "    # Optional: inspect the first test battle\n",
    "    if test_data:\n",
    "        print(\"\\n--- Structure of the first test battle: ---\")\n",
    "        first_test_battle = test_data[0]\n",
    "        test_display = first_test_battle.copy()\n",
    "        test_display['battle_timeline'] = test_display.get('battle_timeline', [])[:2]\n",
    "        print(json.dumps(test_display, indent=4))\n",
    "        if len(first_test_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Could not find the test file at '{test_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8f1dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Per vedere i dati in dataframe, divisi in 4 blocchi dove squadra==p1 e pokemon==p2\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataframe(data) -> []:\n",
    "    df=pd.DataFrame(data)\n",
    "\n",
    "    # DataFrame generale con info di base\n",
    "    df_battle = pd.DataFrame([{\n",
    "        \"battle_id\": b[\"battle_id\"],\n",
    "        \"player_won\": b[\"player_won\"]\n",
    "    } for b in train_data])\n",
    "\n",
    "    # DataFrame con i Pok√©mon della squadra del giocatore (p1_team_details)\n",
    "    df_squad = pd.DataFrame([\n",
    "        {\n",
    "            \"battle_id\": b[\"battle_id\"],\n",
    "            \"pokemon_name\": p[\"name\"],\n",
    "            \"level\": p[\"level\"],\n",
    "            \"types\": p[\"types\"],\n",
    "            \"base_hp\": p[\"base_hp\"],\n",
    "            \"base_atk\": p[\"base_atk\"],\n",
    "            \"base_def\": p[\"base_def\"],\n",
    "            \"base_spa\": p[\"base_spa\"],\n",
    "            \"base_spd\": p[\"base_spd\"],\n",
    "            \"base_spe\": p[\"base_spe\"]\n",
    "        }\n",
    "        for b in train_data\n",
    "        for p in b[\"p1_team_details\"]\n",
    "    ])\n",
    "\n",
    "    # DataFrame con dettagli del lead Pok√©mon dell'avversario\n",
    "    df_pokemon = pd.DataFrame([\n",
    "        {\n",
    "            \"battle_id\": b[\"battle_id\"],\n",
    "            \"name\": b[\"p2_lead_details\"][\"name\"],\n",
    "            \"level\": b[\"p2_lead_details\"][\"level\"],\n",
    "            \"types\": b[\"p2_lead_details\"][\"types\"],\n",
    "            \"base_hp\": b[\"p2_lead_details\"][\"base_hp\"],\n",
    "            \"base_atk\": b[\"p2_lead_details\"][\"base_atk\"],\n",
    "            \"base_def\": b[\"p2_lead_details\"][\"base_def\"],\n",
    "            \"base_spa\": b[\"p2_lead_details\"][\"base_spa\"],\n",
    "            \"base_spd\": b[\"p2_lead_details\"][\"base_spd\"],\n",
    "            \"base_spe\": b[\"p2_lead_details\"][\"base_spe\"]\n",
    "        }\n",
    "        for b in train_data\n",
    "    ])\n",
    "\n",
    "    # DataFrame con la timeline dei turni\n",
    "    df_battle_timeline = pd.DataFrame([\n",
    "        {\n",
    "            \"battle_id\": b[\"battle_id\"],\n",
    "            \"turn\": t[\"turn\"],\n",
    "            \"p1_pokemon\": t[\"p1_pokemon_state\"][\"name\"],\n",
    "            \"p1_hp\": t[\"p1_pokemon_state\"][\"hp_pct\"],\n",
    "            \"p1_status\": t[\"p1_pokemon_state\"][\"status\"],\n",
    "            \"p1_effects\": t[\"p1_pokemon_state\"][\"effects\"],\n",
    "            \"p1_boosts\": t[\"p1_pokemon_state\"][\"boosts\"],\n",
    "            \"p2_pokemon\": t[\"p2_pokemon_state\"][\"name\"],\n",
    "            \"p2_hp\": t[\"p2_pokemon_state\"][\"hp_pct\"],\n",
    "            \"p2_status\": t[\"p2_pokemon_state\"][\"status\"],\n",
    "            \"p2_effects\": t[\"p2_pokemon_state\"][\"effects\"],\n",
    "            \"p2_boosts\": t[\"p2_pokemon_state\"][\"boosts\"],\n",
    "            \"p1_move_name\": t[\"p1_move_details\"][\"name\"] if t[\"p1_move_details\"] else None,\n",
    "            \"p1_move_type\": t[\"p1_move_details\"][\"type\"] if t[\"p1_move_details\"] else None,\n",
    "            \"p1_move_cat\": t[\"p1_move_details\"][\"category\"] if t[\"p1_move_details\"] else None,\n",
    "            \"p1_move_basepow\": t[\"p1_move_details\"][\"base_power\"] if t[\"p1_move_details\"] else None,\n",
    "            \"p1_move_acc\": t[\"p1_move_details\"][\"accuracy\"] if t[\"p1_move_details\"] else None,\n",
    "            \"p1_move_priority\": t[\"p1_move_details\"][\"priority\"] if t[\"p1_move_details\"] else None,\n",
    "            \"p2_move_name\": t[\"p2_move_details\"][\"name\"] if t[\"p2_move_details\"] else None,\n",
    "            \"p2_move_type\": t[\"p2_move_details\"][\"type\"] if t[\"p2_move_details\"] else None,\n",
    "            \"p2_move_cat\": t[\"p2_move_details\"][\"category\"] if t[\"p2_move_details\"] else None,\n",
    "            \"p2_move_basepow\": t[\"p2_move_details\"][\"base_power\"] if t[\"p2_move_details\"] else None,\n",
    "            \"p2_move_acc\": t[\"p2_move_details\"][\"accuracy\"] if t[\"p2_move_details\"] else None,\n",
    "            \"p2_move_priority\": t[\"p2_move_details\"][\"priority\"] if t[\"p2_move_details\"] else None\n",
    "        }\n",
    "        for b in train_data\n",
    "        for t in b[\"battle_timeline\"]\n",
    "    ])\n",
    "\n",
    "    return [df_battle, df_squad, df_pokemon, df_battle_timeline]\n",
    "#train_data e test_data\n",
    "#battle,squad,pokemon,timeline\n",
    "train_list=create_dataframe(train_data)\n",
    "test_list=create_dataframe(test_data)\n",
    "\n",
    "#DEBUG\n",
    "print(len(train_list))\n",
    "print(len(test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3c5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('psychic', 'water'), ('notype', 'psychic'), ('normal', 'notype'), ('electric', 'notype'), ('ice', 'psychic'), ('ghost', 'poison'), ('grass', 'psychic'), ('grass', 'poison'), ('ice', 'water'), ('ground', 'rock'), ('electric', 'flying'), ('dragon', 'flying'), ('fire', 'flying'), ('flying', 'ice')]\n",
      "len combo:  14\n",
      "['dragon', 'electric', 'fire', 'flying', 'ghost', 'grass', 'ground', 'ice', 'normal', 'notype', 'poison', 'psychic', 'rock', 'water']\n",
      "len types:  14\n"
     ]
    }
   ],
   "source": [
    "#Tutti i tipi di pokemon presenti nel mio dataset\n",
    "df_pokemon=train_list[2]\n",
    "df_squad=train_list[1]\n",
    "unique_comb_types = pd.Series(\n",
    "    list(df_pokemon[\"types\"].apply(tuple).unique()) + \n",
    "    list(df_squad[\"types\"].apply(tuple).unique())\n",
    ").drop_duplicates().tolist()\n",
    "\n",
    "print(unique_comb_types)\n",
    "print(\"len combo: \",len(unique_comb_types))\n",
    "\n",
    "unique_types = sorted(\n",
    "    set(\n",
    "        t\n",
    "        for types_list in pd.concat([df_pokemon[\"types\"], df_squad[\"types\"]])\n",
    "        for t in types_list\n",
    "    )\n",
    ")\n",
    "\n",
    "print(unique_types)\n",
    "print(\"len types: \",len(unique_types))\n",
    "\n",
    "#print(\"Effect\\n\",df_battle_timeline[\"p1_effects\"].apply(tuple).unique())\n",
    "#print(\"Move cat\\n\",df_battle_timeline[\"p1_move_cat\"].unique())\n",
    "#print(\"Move type\\n\",df_battle_timeline[\"p1_move_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#controllo che tutti i round arrivino a 30 round\n",
    "df_battle_timeline=train_list[3]\n",
    "print(df_battle_timeline[df_battle_timeline[\"turn\"]==30].count())\n",
    "#ogni match dura 30 round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357c35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentuale di vincitori nel nostro dataset:  50.0\n"
     ]
    }
   ],
   "source": [
    "#controllo per vedere se le classi non sono bilanciate, troppi vincitori nel dataset\n",
    "df_battle=train_list[0]\n",
    "df_battle[\"player_won\"]=df_battle[\"player_won\"].astype(int)\n",
    "perc=df_battle[\"player_won\"].sum()*100/len(df_battle[\"player_won\"])\n",
    "print(\"percentuale di vincitori nel nostro dataset: \",perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aefc968",
   "metadata": {},
   "source": [
    "FUNZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d3732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status unici: ['nostatus', 'par', 'slp', 'fnt', 'frz', 'tox', 'psn', 'brn']\n",
      "EFFECTS unici: ['clamp', 'confusion', 'firespin', 'noeffect', 'reflect', 'substitute', 'typechange', 'wrap']\n"
     ]
    }
   ],
   "source": [
    "#funzione per ottenere tutti i tipi di status e effetti\n",
    "import pandas as pd\n",
    "def unique_se(data_list):\n",
    "    df_battle_timeline=data_list[3]\n",
    "    # Unione dei due campi status\n",
    "    all_status = pd.concat([\n",
    "        df_battle_timeline['p1_status'],\n",
    "        df_battle_timeline['p2_status']\n",
    "    ], ignore_index=True)\n",
    "    unique_status = (\n",
    "        all_status.dropna()\n",
    "        .astype(str)\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "    unique_status = (\n",
    "        all_status.dropna()\n",
    "        .astype(str)\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )   \n",
    "    print(\"status unici:\", unique_status)\n",
    "\n",
    "    all_effects = []\n",
    "\n",
    "    for col in [\"p1_effects\", \"p2_effects\"]:\n",
    "        for row in df_battle_timeline[col].dropna():\n",
    "            if isinstance(row, list):\n",
    "                all_effects.extend(row)\n",
    "            elif isinstance(row, str):\n",
    "                all_effects.append(row)\n",
    "\n",
    "    unique_effects = sorted(set(all_effects))\n",
    "    print(\"EFFECTS unici:\", unique_effects)\n",
    "    return unique_status,unique_effects\n",
    "\n",
    "#unique_status,unique_effects=unique_se(train_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc99f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funzione per ottenere i tipi dei pokemon\n",
    "def unique_t(data_list):\n",
    "    df_pokemon=data_list[2]\n",
    "    df_squad=data_list[1]\n",
    "    unique_types = sorted(\n",
    "        set(\n",
    "            t\n",
    "            for types_list in pd.concat([df_pokemon[\"types\"], df_squad[\"types\"]])\n",
    "            for t in types_list\n",
    "        )\n",
    "    )\n",
    "    return unique_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3a86e",
   "metadata": {},
   "source": [
    "PRIMO MODELLO STATICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a06ac67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creazione del modello da allenare(Statico, prima del match)\n",
    "import pandas as pd\n",
    "def extract_feature(data_list):\n",
    "    df_battle = data_list[0]\n",
    "    df_pokemon = data_list[2]\n",
    "    df_squad = data_list[1]\n",
    "\n",
    "    unique_types = unique_t(data_list)  # funzione che restituisce tutti i tipi unici\n",
    "\n",
    "    # --- PLAYER 1 ---\n",
    "    df_squad[\"types_clean\"] = df_squad[\"types\"].apply(lambda x: [t for t in x if t != \"notype\"])\n",
    "    agg_squad1 = df_squad.groupby(\"battle_id\").agg({\n",
    "        \"base_hp\": \"mean\",\n",
    "        \"base_atk\": \"mean\",\n",
    "        \"base_def\": \"mean\",\n",
    "        \"base_spa\": \"mean\",\n",
    "        \"base_spd\": \"mean\",\n",
    "        \"base_spe\": \"mean\",\n",
    "        \"level\": \"mean\",\n",
    "        \"types_clean\": lambda lst: [t for sub in lst for t in sub]\n",
    "    }).reset_index()\n",
    "    for t in unique_types:\n",
    "        agg_squad1[t] = agg_squad1[\"types_clean\"].apply(lambda lst: lst.count(t))\n",
    "    agg_squad1 = agg_squad1.drop(columns=[\"types_clean\"]).add_prefix(\"p1_\").rename(columns={\"p1_battle_id\": \"battle_id\"})\n",
    "\n",
    "    # --- PLAYER 2 ---\n",
    "    df_squad2 = df_pokemon.copy()\n",
    "    df_squad2[\"types_clean\"] = df_squad2[\"types\"].apply(lambda x: [t for t in x if t != \"notype\"])\n",
    "    for t in unique_types:\n",
    "        df_squad2[t] = df_squad2[\"types_clean\"].apply(lambda lst: lst.count(t))\n",
    "    df_squad2 = df_squad2.drop(columns=[\"types_clean\",\"types\",\"name\"], errors=\"ignore\")\n",
    "    agg_squad2 = df_squad2.add_prefix(\"p2_\").rename(columns={\"p2_battle_id\": \"battle_id\"})\n",
    "\n",
    "    # --- UNIONE FINALE ---\n",
    "    agg_full = agg_squad1.merge(agg_squad2, on=\"battle_id\", how=\"inner\")\n",
    "    agg_full = agg_full.merge(df_battle[[\"battle_id\",\"player_won\"]], on=\"battle_id\", how=\"left\")\n",
    "    agg_full[\"player_won\"] = agg_full[\"player_won\"].astype(int)\n",
    "\n",
    "    return agg_full.fillna(0)\n",
    "\n",
    "\n",
    "#fin_model=extract_feature(train_list)\n",
    "#fin_test_model=extract_feature(test_list)\n",
    "#print(fin_model.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d47f4d",
   "metadata": {},
   "source": [
    "SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7d5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def scale_features(df: pd.DataFrame, exclude_cols: list = None):\n",
    "    \"\"\"\n",
    "    Applica StandardScaler alle colonne numeriche di un DataFrame,\n",
    "    escludendo quelle in exclude_cols (ad es. 'battle_id', 'player_won').\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): il DataFrame da scalare\n",
    "        exclude_cols (list, optional): colonne da escludere dallo scaling\n",
    "\n",
    "    Returns:\n",
    "        df_scaled (pd.DataFrame): DataFrame con feature scalate\n",
    "        scaler (StandardScaler): oggetto scaler gi√† fit\n",
    "    \"\"\"\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "\n",
    "    # Seleziona le colonne da scalare\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "    # Crea una copia per non modificare l'originale\n",
    "    df_scaled = df.copy()\n",
    "\n",
    "    # Inizializza lo scaler e applica fit_transform\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled[feature_cols] = scaler.fit_transform(df_scaled[feature_cols])\n",
    "\n",
    "    return df_scaled, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bee65a",
   "metadata": {},
   "source": [
    "BASIC TRAINING DEL MODELLO BASE(INDICATIVO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac35fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a simple Logistic Regression model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "#TRAIN MODEL(base)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_df=extract_feature(train_list)#our model\n",
    "test_df=extract_feature(test_list)\n",
    "# Define our features (X) and target (y)\n",
    "exclude_cols=['battle_id', 'p1_dragon', 'p1_electric',\n",
    "       'p1_fire', 'p1_flying', 'p1_ghost', 'p1_grass', 'p1_ground', 'p1_ice',\n",
    "       'p1_normal', 'p1_notype', 'p1_poison', 'p1_psychic', 'p1_rock',\n",
    "       'p1_water', 'p2_dragon', 'p2_electric','p2_fire', 'p2_flying',\n",
    "        'p2_ghost', 'p2_grass', 'p2_ground', 'p2_ice','p2_normal',\n",
    "        'p2_notype', 'p2_poison', 'p2_psychic', 'p2_rock',\n",
    "       'p2_water', 'player_won']\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "\n",
    "X_train, scaler = scale_features(train_df, exclude_cols=exclude_cols)\n",
    "\n",
    "y_train = train_df['player_won']\n",
    "\n",
    "# Applica lo stesso scaler al test set\n",
    "X_test_scaled = test_df.copy()\n",
    "X_test_scaled[features] = scaler.transform(X_test_scaled[features])\n",
    "\n",
    "# Initialize and train the model\n",
    "print(\"Training a simple Logistic Regression model...\")\n",
    "model = LogisticRegression(random_state=42, max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed983f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "print(\"Generating predictions on the test set...\")\n",
    "X_test=X_test_scaled\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Probabilit√† di vittoria (utile per metriche tipo ROC AUC)\n",
    "y_test_prob = model.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "# Controlla le prime predizioni\n",
    "print(y_test_pred[:10])\n",
    "print(y_test_prob[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8facee",
   "metadata": {},
   "source": [
    "MODELLO STATICO BASE (ACC=0.51), BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1502c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSS-VALIDATION( K-FOLD )\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "train_df=extract_feature(train_list)\n",
    "\n",
    "#colonne da non scalare\n",
    "type_cols=[ 'p1_dragon', 'p1_electric','p1_fire', 'p1_flying',\n",
    "            'p1_ghost', 'p1_grass', 'p1_ground', 'p1_ice',\n",
    "       'p1_normal', 'p1_notype', 'p1_poison', 'p1_psychic', 'p1_rock',\n",
    "       'p1_water', 'p2_dragon', 'p2_electric','p2_fire', 'p2_flying',\n",
    "        'p2_ghost', 'p2_grass', 'p2_ground', 'p2_ice','p2_normal',\n",
    "        'p2_notype', 'p2_poison', 'p2_psychic', 'p2_rock','p2_water']\n",
    "exclude=['battle_id','player_won']+type_cols\n",
    "\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "\n",
    "#Crea il ColumnTransformer che applichera lo scaler\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', StandardScaler(), features),\n",
    "        ('pass_types', 'passthrough', type_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "#Pipeline per il modello, applica lo scaler dentro ogni fold\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=5000, random_state=42))\n",
    "])\n",
    "\n",
    "#Cross validation\n",
    "X = train_df.drop(columns=['player_won', 'battle_id'])\n",
    "y = train_df['player_won']\n",
    "\n",
    "# K-Fold stratificato\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1','roc_auc']:\n",
    "    s = cross_val_score(pipe, X, y, cv=cv, scoring=metric)\n",
    "    print(f\"{metric.capitalize():<10}: mean={s.mean():.3f} ¬± {s.std():.3f}\")\n",
    "\n",
    "y_pred = cross_val_predict(pipe, X, y, cv=cv)\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbae20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE IMPORTANCE , dopo aver allenato il modello \n",
    "import pandas as pd\n",
    "pipe.fit(X, y)\n",
    "# Estrai il modello finale dalla pipeline\n",
    "model = pipe.named_steps['model']\n",
    "feature_names = pipe.named_steps['preprocessor'].get_feature_names_out()\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "# Crea un DataFrame per associarli ai nomi delle feature\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefs,\n",
    "    'abs_coeff': np.abs(coefs)\n",
    "})\n",
    "\n",
    "# Ordina per importanza assoluta\n",
    "importance = importance.sort_values('abs_coeff', ascending=False)\n",
    "\n",
    "print(\"\\nüîù Top 15 feature pi√π influenti:\")\n",
    "print(importance.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3ca31",
   "metadata": {},
   "source": [
    "BASELINE CON DATI DINAMICI(OTTENUTI DURANTE IL MATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8ea64",
   "metadata": {},
   "source": [
    "funzione feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creazione del modello da allenare(Dinamico , primi 30 round)\n",
    "def extract_all(train_list):\n",
    "    unique_status,unique_effects=unique_se(train_list)\n",
    "    static_features=extract_feature(train_list)\n",
    "    df_battle_timeline = train_list[3]\n",
    "\n",
    "    #Extract dynamic feature\n",
    "    dynamic_features = df_battle_timeline.groupby('battle_id').agg({\n",
    "        'p1_hp': ['mean', 'last'],\n",
    "        'p2_hp': ['mean', 'last'],\n",
    "        'p1_move_basepow': 'mean',\n",
    "        'p2_move_basepow': 'mean',\n",
    "        'p1_move_acc': 'mean',\n",
    "        'p2_move_acc': 'mean',\n",
    "    }).reset_index()\n",
    "    dynamic_features.columns = ['battle_id'] + [f\"{a}_{b}\" for a, b in dynamic_features.columns if a != 'battle_id']\n",
    "    #dynamic_features['hp_diff_mean'] = dynamic_features['p1_hp_mean'] - dynamic_features['p2_hp_mean']\n",
    "\n",
    "    #Merge dataset\n",
    "    train_df = (\n",
    "        static_features\n",
    "        .merge(dynamic_features, on='battle_id', how='left')\n",
    "    )\n",
    "    print(train_df.columns)\n",
    "    return train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e96f7",
   "metadata": {},
   "source": [
    "training con ACC=0.71 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a40e16d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['battle_id', 'p1_base_hp', 'p1_base_atk', 'p1_base_def', 'p1_base_spa',\n",
      "       'p1_base_spd', 'p1_base_spe', 'p1_level', 'p1_dragon', 'p1_electric',\n",
      "       'p1_fire', 'p1_flying', 'p1_ghost', 'p1_grass', 'p1_ground', 'p1_ice',\n",
      "       'p1_normal', 'p1_notype', 'p1_poison', 'p1_psychic', 'p1_rock',\n",
      "       'p1_water', 'p2_level', 'p2_base_hp', 'p2_base_atk', 'p2_base_def',\n",
      "       'p2_base_spa', 'p2_base_spd', 'p2_base_spe', 'p2_dragon', 'p2_electric',\n",
      "       'p2_fire', 'p2_flying', 'p2_ghost', 'p2_grass', 'p2_ground', 'p2_ice',\n",
      "       'p2_normal', 'p2_notype', 'p2_poison', 'p2_psychic', 'p2_rock',\n",
      "       'p2_water', 'player_won', 'p1_hp_mean', 'p1_hp_last', 'p2_hp_mean',\n",
      "       'p2_hp_last', 'p1_move_basepow_mean', 'p2_move_basepow_mean',\n",
      "       'p1_move_acc_mean', 'p2_move_acc_mean'],\n",
      "      dtype='object')\n",
      "['p1_base_hp', 'p1_base_atk', 'p1_base_def', 'p1_base_spa', 'p1_base_spd', 'p1_base_spe', 'p1_level', 'p2_level', 'p2_base_hp', 'p2_base_atk', 'p2_base_def', 'p2_base_spa', 'p2_base_spd', 'p2_base_spe', 'p1_hp_mean', 'p1_hp_last', 'p2_hp_mean', 'p2_hp_last', 'p1_move_basepow_mean', 'p2_move_basepow_mean', 'p1_move_acc_mean', 'p2_move_acc_mean']\n",
      "Accuracy  : mean=0.715 ¬± 0.012\n",
      "Precision : mean=0.716 ¬± 0.014\n",
      "Recall    : mean=0.712 ¬± 0.018\n",
      "F1        : mean=0.714 ¬± 0.012\n",
      "Roc_auc   : mean=0.777 ¬± 0.012\n",
      "[[3588 1412]\n",
      " [1438 3562]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.714     0.718     0.716      5000\n",
      "           1      0.716     0.712     0.714      5000\n",
      "\n",
      "    accuracy                          0.715     10000\n",
      "   macro avg      0.715     0.715     0.715     10000\n",
      "weighted avg      0.715     0.715     0.715     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####################  Train new model-dynamics ##########################\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_df=extract_all(train_list)\n",
    "\n",
    "X = train_df.drop(columns=['player_won', 'battle_id'])\n",
    "y = train_df['player_won']\n",
    "#colonne da non scalare\n",
    "type_cols=[ 'p1_dragon', 'p1_electric','p1_fire', 'p1_flying',\n",
    "            'p1_ghost', 'p1_grass', 'p1_ground', 'p1_ice',\n",
    "       'p1_normal', 'p1_notype', 'p1_poison', 'p1_psychic', 'p1_rock',\n",
    "       'p1_water', 'p2_dragon', 'p2_electric','p2_fire', 'p2_flying',\n",
    "        'p2_ghost', 'p2_grass', 'p2_ground', 'p2_ice','p2_normal',\n",
    "        'p2_notype', 'p2_poison', 'p2_psychic', 'p2_rock','p2_water']\n",
    "exclude=['battle_id','player_won']+type_cols\n",
    "\n",
    "features = [col for col in train_df.columns if col not in exclude]\n",
    "#debug \n",
    "print(features)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), features),\n",
    "    ('pass_types', 'passthrough', type_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=5000, random_state=42))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1','roc_auc']:\n",
    "    s = cross_val_score(pipe, X, y, cv=cv, scoring=metric)\n",
    "    print(f\"{metric.capitalize():<10}: mean={s.mean():.3f} ¬± {s.std():.3f}\")\n",
    "\n",
    "y_pred = cross_val_predict(pipe, X, y, cv=cv)\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f261466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.float64(0.14378000000000002), 'p1_hp_mean'),\n",
       " (np.float64(0.05406000000000004), 'p1_base_hp'),\n",
       " (np.float64(0.04044000000000005), 'p2_hp_mean'),\n",
       " (np.float64(0.03526000000000005), 'p1_psychic'),\n",
       " (np.float64(0.028360000000000073), 'p2_psychic'),\n",
       " (np.float64(0.02110000000000003), 'p1_ice'),\n",
       " (np.float64(0.018140000000000045), 'p1_base_spe'),\n",
       " (np.float64(0.015220000000000056), 'p1_base_def'),\n",
       " (np.float64(0.012560000000000038), 'p2_hp_last'),\n",
       " (np.float64(0.010540000000000039), 'p1_base_atk')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisi feauture per modello dinamico \n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pipe.fit(X, y)\n",
    "r = permutation_importance(pipe, X, y, n_repeats=5, random_state=42)\n",
    "sorted(zip(r.importances_mean, X.columns), reverse=True)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
